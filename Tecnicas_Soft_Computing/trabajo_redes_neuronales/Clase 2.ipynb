{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 2. Regresión para la predición de la calidad del vino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamiento del dataset [**wine-quality**](http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/) y construcción de redes neuronales *Multilayer Perceptron* para predecir la calidad del vino.\n",
    "\n",
    "**Autor**: Nicolás Cubero\n",
    "\n",
    "**Fecha**: 6 de Abril de 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score, r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import RMSprop, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "\n",
    "Primeramente, procedemos a cargar los *datasets* desde los ficheros *csv*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos de los vinos blancos\n",
    "white = pd.read_csv('winequality-white.csv', sep=';')\n",
    "\n",
    "# Cargar los datos de los vinos tinto\n",
    "red = pd.read_csv('winequality-red.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de los datos\n",
    "\n",
    "Una vez cargados los datos, se procede a preprocesar los datos y a prepararlos para alimentar a los modelos *MLP* de regresión en la fase de entrenamiento.\n",
    "\n",
    "En primer lugar, unificamos ambos *datasets* (el *dataset* con instancias de vino blanco y el que contiene instancias de vino tinto)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el atributo \"type\" para identificar los tipos de vinos\n",
    "white['type'] = 0\n",
    "red['type'] = 1\n",
    "\n",
    "# Unificamos ambos datasets en uno único\n",
    "wines = red.append(white, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se separa el conjunto de datos de la etiqueta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomar los datos\n",
    "X = wines.iloc[:, :12]\n",
    "X = X.drop('quality', axis=1)\n",
    "\n",
    "# Tomar la etiqueta\n",
    "y = wines['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalizamos** las variables para evitar que el orden de los valores de las variables provoque que una variable predomine más que otras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilidad para ejecutar la normalización\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normalizar el conjunto de datos\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción de modelos\n",
    "\n",
    "A continuación, usamos los datos preprocesados para entrenar y evaluar diferentes modelos basados en diferentes arquitecturas.\n",
    "\n",
    "Cada modelo será entrenado y evaluado mediante *k-fold* estratificado usando un conjunto de particiones *K=5*.\n",
    "\n",
    "Primeramente, definimos la arquitectura del modelo sobre la cual desarrollaremos los modelos.\n",
    "Se trata de una arquitectura con una única capa oculta de 64 unidades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_MLP():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Primera capa oculta\n",
    "    model.add(Dense(64, input_shape=(11,), activation='relu'))\n",
    "    \n",
    "    # Segunda capa oculta\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a realizar un entrenamiento con estos datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5197/5197 [==============================] - 24s 5ms/step - loss: 1.7338 - mae: 0.8795\n",
      "Epoch 2/10\n",
      "5197/5197 [==============================] - 24s 5ms/step - loss: 0.5902 - mae: 0.5866\n",
      "Epoch 3/10\n",
      "5197/5197 [==============================] - 24s 5ms/step - loss: 0.5430 - mae: 0.5697\n",
      "Epoch 4/10\n",
      "5197/5197 [==============================] - 24s 5ms/step - loss: 0.5293 - mae: 0.5620\n",
      "Epoch 5/10\n",
      "5197/5197 [==============================] - 24s 5ms/step - loss: 0.5157 - mae: 0.5532\n",
      "Epoch 6/10\n",
      "5197/5197 [==============================] - 24s 5ms/step - loss: 0.5135 - mae: 0.5533\n",
      "Epoch 7/10\n",
      "5197/5197 [==============================] - 24s 5ms/step - loss: 0.5125 - mae: 0.5563\n",
      "Epoch 8/10\n",
      "5197/5197 [==============================] - 24s 5ms/step - loss: 0.5033 - mae: 0.5485\n",
      "Epoch 9/10\n",
      "5197/5197 [==============================] - 24s 5ms/step - loss: 0.5018 - mae: 0.5479\n",
      "Epoch 10/10\n",
      "5197/5197 [==============================] - 24s 5ms/step - loss: 0.4955 - mae: 0.5478\n",
      "1300/1300 [==============================] - 0s 99us/step\n",
      "Error MSE:  0.49032466164002053\n",
      "Error MAE:  0.53974449634552\n",
      "Puntuación R2:  0.3577735984865583\n",
      "Epoch 1/10\n",
      "5197/5197 [==============================] - 25s 5ms/step - loss: 1.6906 - mae: 0.8865\n",
      "Epoch 2/10\n",
      "5197/5197 [==============================] - 19s 4ms/step - loss: 0.5935 - mae: 0.5919\n",
      "Epoch 3/10\n",
      "5197/5197 [==============================] - 7s 1ms/step - loss: 0.5473 - mae: 0.5734\n",
      "Epoch 4/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5310 - mae: 0.5624\n",
      "Epoch 5/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5188 - mae: 0.5569\n",
      "Epoch 6/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5177 - mae: 0.5580\n",
      "Epoch 7/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5077 - mae: 0.5559\n",
      "Epoch 8/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5104 - mae: 0.5535\n",
      "Epoch 9/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5011 - mae: 0.5498\n",
      "Epoch 10/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4983 - mae: 0.5469\n",
      "1300/1300 [==============================] - 0s 26us/step\n",
      "Error MSE:  0.5338442483315101\n",
      "Error MAE:  0.5722637176513672\n",
      "Puntuación R2:  0.3007717113716548\n",
      "Epoch 1/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 1.8000 - mae: 0.8976\n",
      "Epoch 2/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5865 - mae: 0.5899\n",
      "Epoch 3/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5372 - mae: 0.5686\n",
      "Epoch 4/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5188 - mae: 0.5563\n",
      "Epoch 5/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5170 - mae: 0.5584\n",
      "Epoch 6/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5087 - mae: 0.5516\n",
      "Epoch 7/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5002 - mae: 0.5480\n",
      "Epoch 8/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4938 - mae: 0.5421\n",
      "Epoch 9/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4906 - mae: 0.5398\n",
      "Epoch 10/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4899 - mae: 0.5421\n",
      "1299/1299 [==============================] - 0s 27us/step\n",
      "Error MSE:  0.5346658015315399\n",
      "Error MAE:  0.5533801317214966\n",
      "Puntuación R2:  0.2968625921009389\n",
      "Epoch 1/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 1.7914 - mae: 0.8993\n",
      "Epoch 2/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.6065 - mae: 0.5964\n",
      "Epoch 3/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5544 - mae: 0.5733\n",
      "Epoch 4/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5315 - mae: 0.5608\n",
      "Epoch 5/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5231 - mae: 0.5573\n",
      "Epoch 6/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5170 - mae: 0.5543\n",
      "Epoch 7/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5095 - mae: 0.5539\n",
      "Epoch 8/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4988 - mae: 0.5432\n",
      "Epoch 9/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4972 - mae: 0.5450\n",
      "Epoch 10/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4975 - mae: 0.5429\n",
      "1299/1299 [==============================] - 0s 26us/step\n",
      "Error MSE:  0.464965473926462\n",
      "Error MAE:  0.5359341502189636\n",
      "Puntuación R2:  0.38930870442852883\n",
      "Epoch 1/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 1.8091 - mae: 0.9050\n",
      "Epoch 2/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.6220 - mae: 0.5961\n",
      "Epoch 3/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5411 - mae: 0.5685\n",
      "Epoch 4/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5261 - mae: 0.5631\n",
      "Epoch 5/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5136 - mae: 0.5552\n",
      "Epoch 6/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5083 - mae: 0.5508\n",
      "Epoch 7/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5040 - mae: 0.5504\n",
      "Epoch 8/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5017 - mae: 0.5456\n",
      "Epoch 9/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4892 - mae: 0.5462\n",
      "Epoch 10/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4910 - mae: 0.5427\n",
      "1299/1299 [==============================] - 0s 26us/step\n",
      "Error MSE:  0.528329458807504\n",
      "Error MAE:  0.5653971433639526\n",
      "Puntuación R2:  0.3080590360788271\n",
      "Error MSE medio:  0.5104259288474072\n",
      "Error MAE medio:  0.55334392786026\n",
      "Puntuación R2 media:  0.3305551284933016\n"
     ]
    }
   ],
   "source": [
    "# Establecer la semilla generadora de números aleatorios\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Realizar particionamiento k-fold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "# Para computar la media de los errores\n",
    "mse_loss_list = []\n",
    "mae_score_list = []\n",
    "r2_score_list = []\n",
    "\n",
    "for train, test in kfold.split(X, y):\n",
    "    model = model_MLP() # Cargar arquitectura\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    # Ajustar el modelo\n",
    "    model.fit(X[train], y[train], epochs=10, verbose=True, batch_size=1)\n",
    "    \n",
    "    # Evaluar el modelo\n",
    "    mse_loss, mae_score = model.evaluate(X[test], y[test])\n",
    "    \n",
    "    mse_loss_list.append(mse_loss)\n",
    "    mae_score_list.append(mae_score)\n",
    "    \n",
    "    # Evaluar la puntuación R2\n",
    "    y_pred = model.predict(X[test])\n",
    "    r2 = r2_score(y[test], y_pred)\n",
    "    \n",
    "    r2_score_list.append(r2)\n",
    "    \n",
    "    # Mostrar la puntuación\n",
    "    print('Error MSE: ', mse_loss)\n",
    "    print('Error MAE: ', mae_score)\n",
    "    print('Puntuación R2: ', r2)\n",
    "\n",
    "# Mostrar puntuación media\n",
    "print('Error MSE medio: ', sum(mse_loss_list)/5)\n",
    "print('Error MAE medio: ', sum(mae_score_list)/5)\n",
    "print('Puntuación R2 media: ', sum(r2_score_list)/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados obtenidos se recogen en la siguiente tabla:\n",
    "\n",
    "| Partición | MSE     | MAE     | R2      |\n",
    "| :-------: | :-----: | :-----: | :-----: |\n",
    "|  K = 1    | 0.49032 | 0.53974 | 0.35777 |\n",
    "|  K = 2    | 0.53844 | 0.57266 | 0.30077 |\n",
    "|  K = 3    | 0.53466 | 0.55338 | 0.29686 |\n",
    "|  K = 4    | 0.46497 | 0.53593 | 0.38931 |\n",
    "|  K = 5    | 0.52833 | 0.56540 | 0.30806 |\n",
    "|  media    | 0.51043 | 0.55334 | 0.33056 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a repetir el experimento considerando 30 épocas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 2.2065 - mae: 0.9546\n",
      "Epoch 2/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5749 - mae: 0.5814\n",
      "Epoch 3/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5326 - mae: 0.5631\n",
      "Epoch 4/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5154 - mae: 0.5541\n",
      "Epoch 5/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5032 - mae: 0.5473\n",
      "Epoch 6/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5001 - mae: 0.5470\n",
      "Epoch 7/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4987 - mae: 0.5483\n",
      "Epoch 8/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4904 - mae: 0.5411\n",
      "Epoch 9/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4879 - mae: 0.5411\n",
      "Epoch 10/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4805 - mae: 0.5382\n",
      "Epoch 11/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4855 - mae: 0.5367\n",
      "Epoch 12/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4758 - mae: 0.5339\n",
      "Epoch 13/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4790 - mae: 0.5352\n",
      "Epoch 14/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4707 - mae: 0.5330\n",
      "Epoch 15/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4669 - mae: 0.5275\n",
      "Epoch 16/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4720 - mae: 0.5319\n",
      "Epoch 17/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4657 - mae: 0.5281\n",
      "Epoch 18/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4672 - mae: 0.5293\n",
      "Epoch 19/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4567 - mae: 0.5262\n",
      "Epoch 20/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4619 - mae: 0.5234\n",
      "Epoch 21/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4584 - mae: 0.5242\n",
      "Epoch 22/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4585 - mae: 0.5243\n",
      "Epoch 23/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4568 - mae: 0.5209\n",
      "Epoch 24/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4572 - mae: 0.5225\n",
      "Epoch 25/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4513 - mae: 0.5172\n",
      "Epoch 26/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4521 - mae: 0.5203\n",
      "Epoch 27/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4510 - mae: 0.5206\n",
      "Epoch 28/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4531 - mae: 0.5178\n",
      "Epoch 29/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4486 - mae: 0.5142\n",
      "Epoch 30/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4454 - mae: 0.5140\n",
      "1300/1300 [==============================] - 0s 27us/step\n",
      "Error MSE:  0.49332691678634055\n",
      "Error MAE:  0.5507293939590454\n",
      "Puntuación R2:  0.35384124789291493\n",
      "Epoch 1/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 1.6549 - mae: 0.8800\n",
      "Epoch 2/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5890 - mae: 0.5904\n",
      "Epoch 3/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5399 - mae: 0.5666\n",
      "Epoch 4/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5208 - mae: 0.5592\n",
      "Epoch 5/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5171 - mae: 0.5580\n",
      "Epoch 6/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5141 - mae: 0.5552\n",
      "Epoch 7/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5079 - mae: 0.5518\n",
      "Epoch 8/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5062 - mae: 0.5508\n",
      "Epoch 9/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5052 - mae: 0.5506\n",
      "Epoch 10/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4954 - mae: 0.5476\n",
      "Epoch 11/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4935 - mae: 0.5426\n",
      "Epoch 12/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4905 - mae: 0.5408\n",
      "Epoch 13/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4819 - mae: 0.5376\n",
      "Epoch 14/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4886 - mae: 0.5393\n",
      "Epoch 15/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4783 - mae: 0.5348\n",
      "Epoch 16/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4797 - mae: 0.5354\n",
      "Epoch 17/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4779 - mae: 0.5346\n",
      "Epoch 18/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4765 - mae: 0.5312\n",
      "Epoch 19/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4726 - mae: 0.5314\n",
      "Epoch 20/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4737 - mae: 0.5297\n",
      "Epoch 21/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4710 - mae: 0.5316\n",
      "Epoch 22/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4694 - mae: 0.5274\n",
      "Epoch 23/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4668 - mae: 0.5297\n",
      "Epoch 24/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4677 - mae: 0.5295\n",
      "Epoch 25/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4645 - mae: 0.5266\n",
      "Epoch 26/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4662 - mae: 0.5263\n",
      "Epoch 27/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4647 - mae: 0.5270\n",
      "Epoch 28/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4623 - mae: 0.5244\n",
      "Epoch 29/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4619 - mae: 0.5245\n",
      "Epoch 30/30\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4563 - mae: 0.5185\n",
      "1300/1300 [==============================] - 0s 25us/step\n",
      "Error MSE:  0.5374394416809082\n",
      "Error MAE:  0.5669806599617004\n",
      "Puntuación R2:  0.29606273897991986\n",
      "Epoch 1/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 1.7647 - mae: 0.8884\n",
      "Epoch 2/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5895 - mae: 0.5884\n",
      "Epoch 3/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5399 - mae: 0.5699\n",
      "Epoch 4/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5275 - mae: 0.5619\n",
      "Epoch 5/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5152 - mae: 0.5555\n",
      "Epoch 6/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5086 - mae: 0.5529\n",
      "Epoch 7/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4970 - mae: 0.5474\n",
      "Epoch 8/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4986 - mae: 0.5465\n",
      "Epoch 9/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4910 - mae: 0.5422\n",
      "Epoch 10/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4885 - mae: 0.5418\n",
      "Epoch 11/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4803 - mae: 0.5394\n",
      "Epoch 12/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4838 - mae: 0.5395\n",
      "Epoch 13/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4736 - mae: 0.5344\n",
      "Epoch 14/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4759 - mae: 0.5350\n",
      "Epoch 15/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4695 - mae: 0.5283\n",
      "Epoch 16/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4711 - mae: 0.5333\n",
      "Epoch 17/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4666 - mae: 0.5283\n",
      "Epoch 18/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4683 - mae: 0.5320\n",
      "Epoch 19/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4633 - mae: 0.5288\n",
      "Epoch 20/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4623 - mae: 0.5282\n",
      "Epoch 21/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4598 - mae: 0.5257\n",
      "Epoch 22/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4604 - mae: 0.5291\n",
      "Epoch 23/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4568 - mae: 0.5277\n",
      "Epoch 24/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4543 - mae: 0.5223\n",
      "Epoch 25/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4532 - mae: 0.5217\n",
      "Epoch 26/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4505 - mae: 0.5213\n",
      "Epoch 27/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4516 - mae: 0.5218\n",
      "Epoch 28/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4516 - mae: 0.5230\n",
      "Epoch 29/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4500 - mae: 0.5199\n",
      "Epoch 30/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4503 - mae: 0.5210\n",
      "1299/1299 [==============================] - 0s 25us/step\n",
      "Error MSE:  0.5302700790834023\n",
      "Error MAE:  0.5684956312179565\n",
      "Puntuación R2:  0.3026433932054049\n",
      "Epoch 1/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 1.7400 - mae: 0.8877\n",
      "Epoch 2/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5772 - mae: 0.5859\n",
      "Epoch 3/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5465 - mae: 0.5672\n",
      "Epoch 4/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5316 - mae: 0.5620\n",
      "Epoch 5/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5201 - mae: 0.5572\n",
      "Epoch 6/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5144 - mae: 0.5555\n",
      "Epoch 7/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5127 - mae: 0.5501\n",
      "Epoch 8/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4968 - mae: 0.5468\n",
      "Epoch 9/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5070 - mae: 0.5497\n",
      "Epoch 10/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4950 - mae: 0.5423\n",
      "Epoch 11/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4884 - mae: 0.5420\n",
      "Epoch 12/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4914 - mae: 0.5410\n",
      "Epoch 13/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4891 - mae: 0.5397\n",
      "Epoch 14/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4838 - mae: 0.5353\n",
      "Epoch 15/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4824 - mae: 0.5338\n",
      "Epoch 16/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4779 - mae: 0.5351\n",
      "Epoch 17/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4762 - mae: 0.5300\n",
      "Epoch 18/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4797 - mae: 0.5306\n",
      "Epoch 19/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4718 - mae: 0.5305\n",
      "Epoch 20/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4688 - mae: 0.5279\n",
      "Epoch 21/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4704 - mae: 0.5292\n",
      "Epoch 22/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4703 - mae: 0.5284\n",
      "Epoch 23/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4709 - mae: 0.5278\n",
      "Epoch 24/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4640 - mae: 0.5257\n",
      "Epoch 25/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4747 - mae: 0.5315\n",
      "Epoch 26/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4599 - mae: 0.5221\n",
      "Epoch 27/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4609 - mae: 0.5250\n",
      "Epoch 28/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4565 - mae: 0.5224\n",
      "Epoch 29/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4578 - mae: 0.5227\n",
      "Epoch 30/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4580 - mae: 0.5163\n",
      "1299/1299 [==============================] - 0s 27us/step\n",
      "Error MSE:  0.585216190192771\n",
      "Error MAE:  0.596242368221283\n",
      "Puntuación R2:  0.2313699440828879\n",
      "Epoch 1/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 1.6815 - mae: 0.8888\n",
      "Epoch 2/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.6015 - mae: 0.5942\n",
      "Epoch 3/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5445 - mae: 0.5704\n",
      "Epoch 4/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5267 - mae: 0.5618\n",
      "Epoch 5/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5213 - mae: 0.5571\n",
      "Epoch 6/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5091 - mae: 0.5513\n",
      "Epoch 7/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5084 - mae: 0.5520\n",
      "Epoch 8/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4982 - mae: 0.5474\n",
      "Epoch 9/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4937 - mae: 0.5452\n",
      "Epoch 10/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4952 - mae: 0.5424\n",
      "Epoch 11/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4879 - mae: 0.5418\n",
      "Epoch 12/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4814 - mae: 0.5368\n",
      "Epoch 13/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4820 - mae: 0.5353\n",
      "Epoch 14/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4768 - mae: 0.5347\n",
      "Epoch 15/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4761 - mae: 0.5330\n",
      "Epoch 16/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4682 - mae: 0.5317\n",
      "Epoch 17/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4723 - mae: 0.5315\n",
      "Epoch 18/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4699 - mae: 0.5317\n",
      "Epoch 19/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4731 - mae: 0.5323\n",
      "Epoch 20/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4631 - mae: 0.5261\n",
      "Epoch 21/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4601 - mae: 0.5264\n",
      "Epoch 22/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4644 - mae: 0.5259\n",
      "Epoch 23/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4615 - mae: 0.5250\n",
      "Epoch 24/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4632 - mae: 0.5254\n",
      "Epoch 25/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4554 - mae: 0.5189\n",
      "Epoch 26/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4603 - mae: 0.5233\n",
      "Epoch 27/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4628 - mae: 0.5258\n",
      "Epoch 28/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4625 - mae: 0.5225\n",
      "Epoch 29/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4648 - mae: 0.5243\n",
      "Epoch 30/30\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4643 - mae: 0.5255\n",
      "1299/1299 [==============================] - 0s 26us/step\n",
      "Error MSE:  0.5220986802225576\n",
      "Error MAE:  0.5564054250717163\n",
      "Puntuación R2:  0.3162193490129258\n",
      "Error MSE medio:  0.533670261593196\n",
      "Error MAE medio:  0.5677706956863403\n",
      "Puntuación R2 media:  0.3000273346348107\n"
     ]
    }
   ],
   "source": [
    "# Establecer la semilla generadora de números aleatorios\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Realizar particionamiento k-fold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "# Para computar la media de los errores\n",
    "mse_loss_list = []\n",
    "mae_score_list = []\n",
    "r2_score_list = []\n",
    "\n",
    "for train, test in kfold.split(X, y):\n",
    "    model = model_MLP() # Cargar arquitectura\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    # Ajustar el modelo\n",
    "    model.fit(X[train], y[train], epochs=30, verbose=True, batch_size=1)\n",
    "    \n",
    "    # Evaluar el modelo\n",
    "    mse_loss, mae_score = model.evaluate(X[test], y[test])\n",
    "    \n",
    "    mse_loss_list.append(mse_loss)\n",
    "    mae_score_list.append(mae_score)\n",
    "    \n",
    "    # Evaluar la puntuación R2\n",
    "    y_pred = model.predict(X[test])\n",
    "    r2 = r2_score(y[test], y_pred)\n",
    "    \n",
    "    r2_score_list.append(r2)\n",
    "    \n",
    "    # Mostrar la puntuación\n",
    "    print('Error MSE: ', mse_loss)\n",
    "    print('Error MAE: ', mae_score)\n",
    "    print('Puntuación R2: ', r2)\n",
    "\n",
    "# Mostrar puntuación media\n",
    "print('Error MSE medio: ', sum(mse_loss_list)/5)\n",
    "print('Error MAE medio: ', sum(mae_score_list)/5)\n",
    "print('Puntuación R2 media: ', sum(r2_score_list)/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando 30 épocas se obtuvieron los siguientes resultados\n",
    "\n",
    "\n",
    "| Partición | MSE     | MAE     | R2      |\n",
    "| :-------: | :-----: | :-----: | :-----: |\n",
    "|  K = 1    | 0.49332 | 0.55073 | 0.35384 |\n",
    "|  K = 2    | 0.53744 | 0.56698 | 0.29606 |\n",
    "|  K = 3    | 0.53027 | 0.56850 | 0.30264 |\n",
    "|  K = 4    | 0.58522 | 0.59624 | 0.23137 |\n",
    "|  K = 5    | 0.52210 | 0.55641 | 0.31622 |\n",
    "|  media    | 0.53367 | 0.56777 | 0.30027 |\n",
    "\n",
    "Comparamos estos resultados con los obtenidos considerando 10 épocas:\n",
    "\n",
    "| Épocas | MSE medio  | MAE medio | R2 medio |\n",
    "| :----: | :--------: | :-------: | :------: |\n",
    "|  10    | 0.51043 | 0.55334 | 0.33056 |\n",
    "|  30    | 0.53367 | 0.56777 | 0.30027 |\n",
    "\n",
    "Se observa que al incrementar el número de épocas de 10 a 30 el rendimiento del modelo empeora. La razón a este fenómeno se explicaría porque la ejecución de un mayor número de épocas permitiría al modelo iniciar y acentuar un sobreajuste a los datos de entrenamiento, con lo que disminuye su capacidad de generalización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incremento en el número de capas\n",
    "\n",
    "A continuación, volvemos a repetir el primer conjunto de experimentos considerando una segunda capa oculta para la arquitectura del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_deep_MLP():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Primera capa oculta\n",
    "    model.add(Dense(64, input_shape=(11,), activation='relu'))\n",
    "    \n",
    "    # Segunda capa oculta\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    \n",
    "    # Tercera capa oculta\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5197/5197 [==============================] - 7s 1ms/step - loss: 1.3356 - mae: 0.8205\n",
      "Epoch 2/10\n",
      "5197/5197 [==============================] - 7s 1ms/step - loss: 0.6390 - mae: 0.6120\n",
      "Epoch 3/10\n",
      "5197/5197 [==============================] - 7s 1ms/step - loss: 0.5856 - mae: 0.5904\n",
      "Epoch 4/10\n",
      "5197/5197 [==============================] - 7s 1ms/step - loss: 0.5622 - mae: 0.5834\n",
      "Epoch 5/10\n",
      "5197/5197 [==============================] - 7s 1ms/step - loss: 0.5429 - mae: 0.5711\n",
      "Epoch 6/10\n",
      "5197/5197 [==============================] - 7s 1ms/step - loss: 0.5277 - mae: 0.5628\n",
      "Epoch 7/10\n",
      "5197/5197 [==============================] - 7s 1ms/step - loss: 0.5339 - mae: 0.5641\n",
      "Epoch 8/10\n",
      "5197/5197 [==============================] - 7s 1ms/step - loss: 0.5163 - mae: 0.5598\n",
      "Epoch 9/10\n",
      "5197/5197 [==============================] - 7s 1ms/step - loss: 0.5136 - mae: 0.5534\n",
      "Epoch 10/10\n",
      "5197/5197 [==============================] - 7s 1ms/step - loss: 0.5109 - mae: 0.5536\n",
      "1300/1300 [==============================] - 0s 26us/step\n",
      "Error MSE:  0.4836191951770049\n",
      "Error MAE:  0.5374965071678162\n",
      "Puntuación R2:  0.3665563957203848\n",
      "Epoch 1/10\n",
      "5197/5197 [==============================] - 7s 1ms/step - loss: 1.3585 - mae: 0.8345\n",
      "Epoch 2/10\n",
      "5197/5197 [==============================] - 7s 1ms/step - loss: 0.6283 - mae: 0.6175\n",
      "Epoch 3/10\n",
      "5197/5197 [==============================] - 7s 1ms/step - loss: 0.5797 - mae: 0.5927\n",
      "Epoch 4/10\n",
      "5197/5197 [==============================] - 7s 1ms/step - loss: 0.5595 - mae: 0.5827\n",
      "Epoch 5/10\n",
      "5197/5197 [==============================] - 7s 1ms/step - loss: 0.5413 - mae: 0.5704\n",
      "Epoch 6/10\n",
      "5197/5197 [==============================] - 7s 1ms/step - loss: 0.5334 - mae: 0.5644\n",
      "Epoch 7/10\n",
      "5197/5197 [==============================] - 7s 1ms/step - loss: 0.5254 - mae: 0.5633\n",
      "Epoch 8/10\n",
      "5197/5197 [==============================] - 7s 1ms/step - loss: 0.5213 - mae: 0.5625\n",
      "Epoch 9/10\n",
      "5197/5197 [==============================] - 7s 1ms/step - loss: 0.5123 - mae: 0.5510\n",
      "Epoch 10/10\n",
      "5197/5197 [==============================] - 7s 1ms/step - loss: 0.5087 - mae: 0.5527\n",
      "1300/1300 [==============================] - 0s 26us/step\n",
      "Error MSE:  0.4998632975725027\n",
      "Error MAE:  0.5456662178039551\n",
      "Puntuación R2:  0.3452799095687381\n",
      "Epoch 1/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 1.2637 - mae: 0.8179\n",
      "Epoch 2/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.6123 - mae: 0.6070\n",
      "Epoch 3/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.5713 - mae: 0.5861\n",
      "Epoch 4/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.5484 - mae: 0.5715\n",
      "Epoch 5/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.5461 - mae: 0.5726\n",
      "Epoch 6/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.5262 - mae: 0.5673\n",
      "Epoch 7/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.5247 - mae: 0.5612\n",
      "Epoch 8/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.5135 - mae: 0.5562\n",
      "Epoch 9/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.5067 - mae: 0.5547\n",
      "Epoch 10/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.4992 - mae: 0.5477\n",
      "1299/1299 [==============================] - 0s 28us/step\n",
      "Error MSE:  0.5310557401804303\n",
      "Error MAE:  0.5528169870376587\n",
      "Puntuación R2:  0.30161018019227837\n",
      "Epoch 1/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 1.3862 - mae: 0.8337\n",
      "Epoch 2/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.6220 - mae: 0.6098\n",
      "Epoch 3/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.5842 - mae: 0.5879\n",
      "Epoch 4/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.5619 - mae: 0.5780\n",
      "Epoch 5/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.5470 - mae: 0.5710\n",
      "Epoch 6/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.5347 - mae: 0.5655\n",
      "Epoch 7/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.5320 - mae: 0.5676\n",
      "Epoch 8/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.5200 - mae: 0.5554\n",
      "Epoch 9/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.5192 - mae: 0.5572\n",
      "Epoch 10/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.5131 - mae: 0.5505\n",
      "1299/1299 [==============================] - 0s 28us/step\n",
      "Error MSE:  0.4709541430328331\n",
      "Error MAE:  0.5368170738220215\n",
      "Puntuación R2:  0.38144310480818033\n",
      "Epoch 1/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 1.4146 - mae: 0.8238\n",
      "Epoch 2/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.6306 - mae: 0.6142\n",
      "Epoch 3/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.5902 - mae: 0.5940\n",
      "Epoch 4/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.5664 - mae: 0.5832\n",
      "Epoch 5/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.5407 - mae: 0.5727\n",
      "Epoch 6/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.5344 - mae: 0.5631\n",
      "Epoch 7/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.5282 - mae: 0.5629\n",
      "Epoch 8/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.5207 - mae: 0.5547\n",
      "Epoch 9/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.5036 - mae: 0.5558\n",
      "Epoch 10/10\n",
      "5198/5198 [==============================] - 7s 1ms/step - loss: 0.5089 - mae: 0.5514\n",
      "1299/1299 [==============================] - 0s 28us/step\n",
      "Error MSE:  0.4846808333136285\n",
      "Error MAE:  0.5382589101791382\n",
      "Puntuación R2:  0.3652246399807414\n",
      "Error MSE medio:  0.49403464185527984\n",
      "Error MAE medio:  0.5422111392021179\n",
      "Puntuación R2 media:  0.3520228460540646\n"
     ]
    }
   ],
   "source": [
    "# Establecer la semilla generadora de números aleatorios\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Realizar particionamiento k-fold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "# Para computar la media de los errores\n",
    "mse_loss_list = []\n",
    "mae_score_list = []\n",
    "r2_score_list = []\n",
    "\n",
    "for train, test in kfold.split(X, y):\n",
    "    model = model_deep_MLP() # Cargar arquitectura\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    # Ajustar el modelo\n",
    "    model.fit(X[train], y[train], epochs=10, verbose=True, batch_size=1)\n",
    "    \n",
    "    # Evaluar el modelo\n",
    "    mse_loss, mae_score = model.evaluate(X[test], y[test])\n",
    "    \n",
    "    mse_loss_list.append(mse_loss)\n",
    "    mae_score_list.append(mae_score)\n",
    "    \n",
    "    # Evaluar la puntuación R2\n",
    "    y_pred = model.predict(X[test])\n",
    "    r2 = r2_score(y[test], y_pred)\n",
    "    \n",
    "    r2_score_list.append(r2)\n",
    "    \n",
    "    # Mostrar la puntuación\n",
    "    print('Error MSE: ', mse_loss)\n",
    "    print('Error MAE: ', mae_score)\n",
    "    print('Puntuación R2: ', r2)\n",
    "\n",
    "# Mostrar puntuación media\n",
    "print('Error MSE medio: ', sum(mse_loss_list)/5)\n",
    "print('Error MAE medio: ', sum(mae_score_list)/5)\n",
    "print('Puntuación R2 media: ', sum(r2_score_list)/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando un mayor número de capas intermedias se obtienen los siguientes resultados:\n",
    "\n",
    "\n",
    "| Partición | MSE     | MAE     | R2      |\n",
    "| :-------: | :-----: | :-----: | :-----: |\n",
    "|  K = 1    | 0.48362 | 0.53749 | 0.36656 |\n",
    "|  K = 2    | 0.49986 | 0.54567 | 0.34528 |\n",
    "|  K = 3    | 0.53106 | 0.55282 | 0.30161 |\n",
    "|  K = 4    | 0.47095 | 0.53682 | 0.38144 |\n",
    "|  K = 5    | 0.48487 | 0.53836 | 0.36522 |\n",
    "|  media    | 0.49403 | 0.54221 | 0.35202 |\n",
    "\n",
    "Comparamos estos resultados con los obtenidos considerando 10 épocas:\n",
    "\n",
    "| Modelo    | MSE medio  | MAE medio | R2 medio |\n",
    "| :-------: | :--------: | :-------: | :------: |\n",
    "| Básico    | 0.51043    | 0.55334   | 0.33056  |\n",
    "| Más capas | 0.49403    | 0.54221   | 0.35202  |\n",
    "\n",
    "Se aprecia que, ante un mayor número de capas, el rendimiento del modelo mejora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incremento en el número de nodos\n",
    "\n",
    "Se probará ahora, a desarrollar otro modelo basado en la primera arquitectura probando un mayor número de nodos en la capa intermedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_larger_MLP():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Primera capa oculta\n",
    "    model.add(Dense(128, input_shape=(11,), activation='relu'))\n",
    "    \n",
    "    # Tercera capa oculta\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 1.5018 - mae: 0.8192\n",
      "Epoch 2/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5853 - mae: 0.5860\n",
      "Epoch 3/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5503 - mae: 0.5727\n",
      "Epoch 4/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5339 - mae: 0.5664\n",
      "Epoch 5/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5176 - mae: 0.5543\n",
      "Epoch 6/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5157 - mae: 0.5541\n",
      "Epoch 7/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5153 - mae: 0.5569\n",
      "Epoch 8/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5034 - mae: 0.5473\n",
      "Epoch 9/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5008 - mae: 0.5476\n",
      "Epoch 10/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4932 - mae: 0.5459\n",
      "1300/1300 [==============================] - 0s 26us/step\n",
      "Error MSE:  0.4839323749909034\n",
      "Error MAE:  0.5371947288513184\n",
      "Puntuación R2:  0.3661461944379417\n",
      "Epoch 1/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 1.4031 - mae: 0.8081\n",
      "Epoch 2/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5804 - mae: 0.5888\n",
      "Epoch 3/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5486 - mae: 0.5754\n",
      "Epoch 4/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5356 - mae: 0.5657\n",
      "Epoch 5/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5209 - mae: 0.5584\n",
      "Epoch 6/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5182 - mae: 0.5593\n",
      "Epoch 7/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5128 - mae: 0.5594\n",
      "Epoch 8/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5112 - mae: 0.5521\n",
      "Epoch 9/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5038 - mae: 0.5490\n",
      "Epoch 10/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.4951 - mae: 0.5439\n",
      "1300/1300 [==============================] - 0s 26us/step\n",
      "Error MSE:  0.5229738198793852\n",
      "Error MAE:  0.5612230896949768\n",
      "Puntuación R2:  0.31500978633545373\n",
      "Epoch 1/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 1.4573 - mae: 0.8271\n",
      "Epoch 2/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5828 - mae: 0.5887\n",
      "Epoch 3/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5424 - mae: 0.5738\n",
      "Epoch 4/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5230 - mae: 0.5617\n",
      "Epoch 5/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5229 - mae: 0.5643\n",
      "Epoch 6/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5101 - mae: 0.5580\n",
      "Epoch 7/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5032 - mae: 0.5525\n",
      "Epoch 8/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4930 - mae: 0.5439\n",
      "Epoch 9/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4907 - mae: 0.5426\n",
      "Epoch 10/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4909 - mae: 0.5434\n",
      "1299/1299 [==============================] - 0s 25us/step\n",
      "Error MSE:  0.5227127542304846\n",
      "Error MAE:  0.5497487187385559\n",
      "Puntuación R2:  0.3125820084704902\n",
      "Epoch 1/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 1.4344 - mae: 0.8128\n",
      "Epoch 2/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5962 - mae: 0.5928\n",
      "Epoch 3/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5583 - mae: 0.5750\n",
      "Epoch 4/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5384 - mae: 0.5658\n",
      "Epoch 5/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5280 - mae: 0.5613\n",
      "Epoch 6/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5219 - mae: 0.5566\n",
      "Epoch 7/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5140 - mae: 0.5566\n",
      "Epoch 8/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5038 - mae: 0.5451\n",
      "Epoch 9/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5011 - mae: 0.5475\n",
      "Epoch 10/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5018 - mae: 0.5448\n",
      "1299/1299 [==============================] - 0s 28us/step\n",
      "Error MSE:  0.4693372975504334\n",
      "Error MAE:  0.5353826284408569\n",
      "Puntuación R2:  0.3835666922989248\n",
      "Epoch 1/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 1.5127 - mae: 0.8235\n",
      "Epoch 2/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5809 - mae: 0.5868\n",
      "Epoch 3/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5456 - mae: 0.5734\n",
      "Epoch 4/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5324 - mae: 0.5671\n",
      "Epoch 5/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5156 - mae: 0.5595\n",
      "Epoch 6/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5115 - mae: 0.5520\n",
      "Epoch 7/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5098 - mae: 0.5545\n",
      "Epoch 8/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5062 - mae: 0.5487\n",
      "Epoch 9/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4929 - mae: 0.5499\n",
      "Epoch 10/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.4948 - mae: 0.5437\n",
      "1299/1299 [==============================] - 0s 32us/step\n",
      "Error MSE:  0.5360640251379549\n",
      "Error MAE:  0.5735675692558289\n",
      "Puntuación R2:  0.2979292529467451\n",
      "Error MSE medio:  0.5070040543578324\n",
      "Error MAE medio:  0.5514233469963074\n",
      "Puntuación R2 media:  0.3350467868979111\n"
     ]
    }
   ],
   "source": [
    "# Establecer la semilla generadora de números aleatorios\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Realizar particionamiento k-fold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "# Para computar la media de los errores\n",
    "mse_loss_list = []\n",
    "mae_score_list = []\n",
    "r2_score_list = []\n",
    "\n",
    "for train, test in kfold.split(X, y):\n",
    "    model = model_larger_MLP() # Cargar arquitectura\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    # Ajustar el modelo\n",
    "    model.fit(X[train], y[train], epochs=10, verbose=True, batch_size=1)\n",
    "    \n",
    "    # Evaluar el modelo\n",
    "    mse_loss, mae_score = model.evaluate(X[test], y[test])\n",
    "    \n",
    "    mse_loss_list.append(mse_loss)\n",
    "    mae_score_list.append(mae_score)\n",
    "    \n",
    "    # Evaluar la puntuación R2\n",
    "    y_pred = model.predict(X[test])\n",
    "    r2 = r2_score(y[test], y_pred)\n",
    "    \n",
    "    r2_score_list.append(r2)\n",
    "    \n",
    "    # Mostrar la puntuación\n",
    "    print('Error MSE: ', mse_loss)\n",
    "    print('Error MAE: ', mae_score)\n",
    "    print('Puntuación R2: ', r2)\n",
    "\n",
    "# Mostrar puntuación media\n",
    "print('Error MSE medio: ', sum(mse_loss_list)/5)\n",
    "print('Error MAE medio: ', sum(mae_score_list)/5)\n",
    "print('Puntuación R2 media: ', sum(r2_score_list)/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando un mayor número de nodos en la capa oculta se obtienen los siguientes resultados:\n",
    "\n",
    "\n",
    "| Partición | MSE     | MAE     | R2      |\n",
    "| :-------: | :-----: | :-----: | :-----: |\n",
    "|  K = 1    | 0.48393 | 0.53719 | 0.36614 |\n",
    "|  K = 2    | 0.52297 | 0.56122 | 0.31501 |\n",
    "|  K = 3    | 0.52271 | 0.54975 | 0.31258 |\n",
    "|  K = 4    | 0.46934 | 0.53538 | 0.38568 |\n",
    "|  K = 5    | 0.53606 | 0.57357 | 0.29793 |\n",
    "|  media    | 0.50700 | 0.55142 | 0.33505 |\n",
    "\n",
    "Comparamos estos resultados con los obtenidos con el modelo original:\n",
    "\n",
    "| Modelo       | MSE medio  | MAE medio | R2 medio |\n",
    "| :----------: | :--------: | :-------: | :------: |\n",
    "| Básico       | 0.51043    | 0.55334   | 0.33056  |\n",
    "| Más unidades | 0.50700    | 0.55142   | 0.33505 |\n",
    "\n",
    "En este caso, al incrementar el número de nodos, el rendimiento del nodo ha mejorado ligeramente.\n",
    "\n",
    "Incrementar el número de nodos y/o el número de capas en la arquitectura resulta útil para permitir al modelo asimilar mayor cantidad de información del conjunto de datos de entrenamiento. No obstante, incrementar en exceso esta complejidad en la arquitectura puede tener 2 efectos negativos:\n",
    "\n",
    "1. Incremento en el tiempo de cómputo necesario para entrenar el modelo y/o realizar prediciones con él.\n",
    "2. Sobreajuste a los datos de entrenamiento (el modelo también aprendería el ruido contenido en el conjunto de datos), lo que perjudica a la capacidad de generalización del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducción de la tasa de aprendizaje\n",
    "\n",
    "Se prueba, a continuación, a desarrollar otra experimentación usando la arquitectura original, pero estableciendo una tasa de aprendizaje (*learning rate*) menor en el optimizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 10.8993 - mae: 2.6463\n",
      "Epoch 2/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 1.4776 - mae: 0.9259\n",
      "Epoch 3/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 1.1461 - mae: 0.8106\n",
      "Epoch 4/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.9474 - mae: 0.7320\n",
      "Epoch 5/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.8139 - mae: 0.6783\n",
      "Epoch 6/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.7308 - mae: 0.6421\n",
      "Epoch 7/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.6660 - mae: 0.6154\n",
      "Epoch 8/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.6248 - mae: 0.5958\n",
      "Epoch 9/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5945 - mae: 0.5808\n",
      "Epoch 10/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5717 - mae: 0.5709\n",
      "1300/1300 [==============================] - 0s 25us/step\n",
      "Error MSE:  0.5577689889761118\n",
      "Error MAE:  0.5748510956764221\n",
      "Puntuación R2:  0.26943512930575797\n",
      "Epoch 1/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 10.4305 - mae: 2.5912\n",
      "Epoch 2/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 1.3488 - mae: 0.8933\n",
      "Epoch 3/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 1.0776 - mae: 0.7895\n",
      "Epoch 4/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.9178 - mae: 0.7263\n",
      "Epoch 5/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.8109 - mae: 0.6814\n",
      "Epoch 6/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.7269 - mae: 0.6492\n",
      "Epoch 7/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.6744 - mae: 0.6255\n",
      "Epoch 8/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.6350 - mae: 0.6081\n",
      "Epoch 9/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.6026 - mae: 0.5940\n",
      "Epoch 10/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.5796 - mae: 0.5831\n",
      "1300/1300 [==============================] - 0s 26us/step\n",
      "Error MSE:  0.6654192352294922\n",
      "Error MAE:  0.5957720279693604\n",
      "Puntuación R2:  0.12843501856891215\n",
      "Epoch 1/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 10.0970 - mae: 2.5313\n",
      "Epoch 2/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 1.4719 - mae: 0.9287\n",
      "Epoch 3/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 1.1462 - mae: 0.8090\n",
      "Epoch 4/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.9735 - mae: 0.7390\n",
      "Epoch 5/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.8620 - mae: 0.6917\n",
      "Epoch 6/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.7724 - mae: 0.6563\n",
      "Epoch 7/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.7100 - mae: 0.6304\n",
      "Epoch 8/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.6604 - mae: 0.6092\n",
      "Epoch 9/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.6251 - mae: 0.5951\n",
      "Epoch 10/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.6028 - mae: 0.5838\n",
      "1299/1299 [==============================] - 0s 25us/step\n",
      "Error MSE:  0.602486112651869\n",
      "Error MAE:  0.5830479860305786\n",
      "Puntuación R2:  0.20767230615046184\n",
      "Epoch 1/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 7.9372 - mae: 2.2312\n",
      "Epoch 2/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 1.5111 - mae: 0.9308\n",
      "Epoch 3/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 1.2242 - mae: 0.8316\n",
      "Epoch 4/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 1.0302 - mae: 0.7604\n",
      "Epoch 5/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.8907 - mae: 0.7066\n",
      "Epoch 6/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.7914 - mae: 0.6656\n",
      "Epoch 7/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.7127 - mae: 0.6349\n",
      "Epoch 8/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.6605 - mae: 0.6124\n",
      "Epoch 9/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.6111 - mae: 0.5926\n",
      "Epoch 10/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.5820 - mae: 0.5791\n",
      "1299/1299 [==============================] - 0s 28us/step\n",
      "Error MSE:  0.5737642587791323\n",
      "Error MAE:  0.5863515138626099\n",
      "Puntuación R2:  0.24641105202662894\n",
      "Epoch 1/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 10.5261 - mae: 2.6233\n",
      "Epoch 2/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 1.3485 - mae: 0.8820\n",
      "Epoch 3/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 1.0752 - mae: 0.7787\n",
      "Epoch 4/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.9329 - mae: 0.7180\n",
      "Epoch 5/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.8300 - mae: 0.6771\n",
      "Epoch 6/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.7549 - mae: 0.6488\n",
      "Epoch 7/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.7005 - mae: 0.6252\n",
      "Epoch 8/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.6596 - mae: 0.6086\n",
      "Epoch 9/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.6208 - mae: 0.5949\n",
      "Epoch 10/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.6036 - mae: 0.5852\n",
      "1299/1299 [==============================] - 0s 27us/step\n",
      "Error MSE:  0.587994073403625\n",
      "Error MAE:  0.5887799263000488\n",
      "Puntuación R2:  0.22991765567064526\n",
      "Error MSE medio:  0.5974865338080461\n",
      "Error MAE medio:  0.5857605099678039\n",
      "Puntuación R2 media:  0.21637423234448122\n"
     ]
    }
   ],
   "source": [
    "# Establecer la semilla generadora de números aleatorios\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Cargar y configurar el optimizador\n",
    "rmsprop = RMSprop(lr = 1e-4)\n",
    "\n",
    "# Realizar particionamiento k-fold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "# Para computar la media de los errores\n",
    "mse_loss_list = []\n",
    "mae_score_list = []\n",
    "r2_score_list = []\n",
    "\n",
    "for train, test in kfold.split(X, y):\n",
    "    model = model_MLP() # Cargar arquitectura\n",
    "    model.compile(optimizer=rmsprop, loss='mse', metrics=['mae'])\n",
    "    \n",
    "    # Ajustar el modelo\n",
    "    model.fit(X[train], y[train], epochs=10, verbose=True, batch_size=1)\n",
    "    \n",
    "    # Evaluar el modelo\n",
    "    mse_loss, mae_score = model.evaluate(X[test], y[test])\n",
    "    \n",
    "    mse_loss_list.append(mse_loss)\n",
    "    mae_score_list.append(mae_score)\n",
    "    \n",
    "    # Evaluar la puntuación R2\n",
    "    y_pred = model.predict(X[test])\n",
    "    r2 = r2_score(y[test], y_pred)\n",
    "    \n",
    "    r2_score_list.append(r2)\n",
    "    \n",
    "    # Mostrar la puntuación\n",
    "    print('Error MSE: ', mse_loss)\n",
    "    print('Error MAE: ', mae_score)\n",
    "    print('Puntuación R2: ', r2)\n",
    "\n",
    "# Mostrar puntuación media\n",
    "print('Error MSE medio: ', sum(mse_loss_list)/5)\n",
    "print('Error MAE medio: ', sum(mae_score_list)/5)\n",
    "print('Puntuación R2 media: ', sum(r2_score_list)/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este descenso del *learning rate*, se han obtenido los siguientes resultados:\n",
    "\n",
    "\n",
    "| Partición | MSE     | MAE     | R2      |\n",
    "| :-------: | :-----: | :-----: | :-----: |\n",
    "|  K = 1    | 0.55777 | 0.57485 | 0.26944 |\n",
    "|  K = 2    | 0.66542 | 0.59577 | 0.12844 |\n",
    "|  K = 3    | 0.60249 | 0.58305 | 0.20767 |\n",
    "|  K = 4    | 0.57376 | 0.58635 | 0.24641 |\n",
    "|  K = 5    | 0.58799 | 0.58877 | 0.22991 |\n",
    "|  media    | 0.59749 | 0.58576 | 0.21637 |\n",
    "\n",
    "Comparamos estos resultados con los obtenidos con el modelo original:\n",
    "\n",
    "| Modelo       | MSE medio  | MAE medio | R2 medio |\n",
    "| :----------: | :--------: | :-------: | :------: |\n",
    "| Básico   | 0.51043    | 0.55334   | 0.33056  |\n",
    "| Menor lr | 0.59749 | 0.58576 | 0.21637 |\n",
    "\n",
    "Se aprecia que el rendimiento del modelo ha empeorado. Al disminuir la tasa de aprendizaje, el ajuste del modelo se desarrolla más lentamente, lo que provoca que el modelo necesite un mayor número de *epochs* para alcanzar el mismo óptimo local que el modelo original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incremento de la tasa de aprendizaje\n",
    "\n",
    "Por último, repetimos el experimento anterior incrementando el *learning rate*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 3.0003 - mae: 0.9733\n",
      "Epoch 2/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 1.0805 - mae: 0.7464\n",
      "Epoch 3/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 1.0766 - mae: 0.7398\n",
      "Epoch 4/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.9181 - mae: 0.7164\n",
      "Epoch 5/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.8609 - mae: 0.7096\n",
      "Epoch 6/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.8264 - mae: 0.7094\n",
      "Epoch 7/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.8253 - mae: 0.7100\n",
      "Epoch 8/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.8079 - mae: 0.7063\n",
      "Epoch 9/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.8977 - mae: 0.7082\n",
      "Epoch 10/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.8248 - mae: 0.7050\n",
      "1300/1300 [==============================] - 0s 29us/step\n",
      "Error MSE:  0.7717360491019029\n",
      "Error MAE:  0.7002520561218262\n",
      "Puntuación R2:  -0.010818599794694128\n",
      "Epoch 1/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 3.1014 - mae: 0.9864\n",
      "Epoch 2/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 1.1231 - mae: 0.7598\n",
      "Epoch 3/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.9716 - mae: 0.7330\n",
      "Epoch 4/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 1.0662 - mae: 0.7362\n",
      "Epoch 5/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.8601 - mae: 0.7113\n",
      "Epoch 6/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.8258 - mae: 0.7081\n",
      "Epoch 7/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.8792 - mae: 0.7147\n",
      "Epoch 8/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.8836 - mae: 0.7169\n",
      "Epoch 9/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.8290 - mae: 0.7101\n",
      "Epoch 10/10\n",
      "5197/5197 [==============================] - 6s 1ms/step - loss: 0.8461 - mae: 0.7066\n",
      "1300/1300 [==============================] - 0s 27us/step\n",
      "Error MSE:  0.9207562952775221\n",
      "Error MAE:  0.6823970079421997\n",
      "Puntuación R2:  -0.20600501946983552\n",
      "Epoch 1/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 2.7237 - mae: 0.9696\n",
      "Epoch 2/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 1.2028 - mae: 0.7526\n",
      "Epoch 3/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 1.0269 - mae: 0.7466\n",
      "Epoch 4/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 1.0431 - mae: 0.7287\n",
      "Epoch 5/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.9904 - mae: 0.7221\n",
      "Epoch 6/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.8678 - mae: 0.7183\n",
      "Epoch 7/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.9220 - mae: 0.7164\n",
      "Epoch 8/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.9563 - mae: 0.7146\n",
      "Epoch 9/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.8695 - mae: 0.7121\n",
      "Epoch 10/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.9832 - mae: 0.7145\n",
      "1299/1299 [==============================] - 0s 28us/step\n",
      "Error MSE:  0.8406624231914817\n",
      "Error MAE:  0.760441780090332\n",
      "Puntuación R2:  -0.10555269586399119\n",
      "Epoch 1/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 2.6606 - mae: 0.9766\n",
      "Epoch 2/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 1.3744 - mae: 0.7737\n",
      "Epoch 3/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 1.1267 - mae: 0.7406\n",
      "Epoch 4/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.9579 - mae: 0.7278\n",
      "Epoch 5/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 1.0436 - mae: 0.7238\n",
      "Epoch 6/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.9828 - mae: 0.7199\n",
      "Epoch 7/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.8253 - mae: 0.7116\n",
      "Epoch 8/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.8178 - mae: 0.7096\n",
      "Epoch 9/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.8098 - mae: 0.7081\n",
      "Epoch 10/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.8717 - mae: 0.7125\n",
      "1299/1299 [==============================] - 0s 28us/step\n",
      "Error MSE:  0.9080526859049984\n",
      "Error MAE:  0.7169714570045471\n",
      "Puntuación R2:  -0.19264741485629866\n",
      "Epoch 1/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 3.7534 - mae: 1.0288\n",
      "Epoch 2/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 1.5625 - mae: 0.7723\n",
      "Epoch 3/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 1.3215 - mae: 0.7576\n",
      "Epoch 4/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 1.2421 - mae: 0.7272\n",
      "Epoch 5/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.9158 - mae: 0.7254\n",
      "Epoch 6/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.8725 - mae: 0.7143\n",
      "Epoch 7/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.8589 - mae: 0.7069\n",
      "Epoch 8/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.8852 - mae: 0.7132\n",
      "Epoch 9/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.8733 - mae: 0.7080\n",
      "Epoch 10/10\n",
      "5198/5198 [==============================] - 6s 1ms/step - loss: 0.8904 - mae: 0.7081\n",
      "1299/1299 [==============================] - 0s 25us/step\n",
      "Error MSE:  0.8940473023151049\n",
      "Error MAE:  0.7443552613258362\n",
      "Puntuación R2:  -0.17091317059309086\n",
      "Error MSE medio:  0.8670509511582021\n",
      "Error MAE medio:  0.7208835124969483\n",
      "Puntuación R2 media:  -0.13718738011558207\n"
     ]
    }
   ],
   "source": [
    "# Establecer la semilla generadora de números aleatorios\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Cargar y configurar el optimizador\n",
    "rmsprop = RMSprop(lr = 0.1)\n",
    "\n",
    "# Realizar particionamiento k-fold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "# Para computar la media de los errores\n",
    "mse_loss_list = []\n",
    "mae_score_list = []\n",
    "r2_score_list = []\n",
    "\n",
    "for train, test in kfold.split(X, y):\n",
    "    model = model_MLP() # Cargar arquitectura\n",
    "    model.compile(optimizer=rmsprop, loss='mse', metrics=['mae'])\n",
    "    \n",
    "    # Ajustar el modelo\n",
    "    model.fit(X[train], y[train], epochs=10, verbose=True, batch_size=1)\n",
    "    \n",
    "    # Evaluar el modelo\n",
    "    mse_loss, mae_score = model.evaluate(X[test], y[test])\n",
    "    \n",
    "    mse_loss_list.append(mse_loss)\n",
    "    mae_score_list.append(mae_score)\n",
    "    \n",
    "    # Evaluar la puntuación R2\n",
    "    y_pred = model.predict(X[test])\n",
    "    r2 = r2_score(y[test], y_pred)\n",
    "    \n",
    "    r2_score_list.append(r2)\n",
    "    \n",
    "    # Mostrar la puntuación\n",
    "    print('Error MSE: ', mse_loss)\n",
    "    print('Error MAE: ', mae_score)\n",
    "    print('Puntuación R2: ', r2)\n",
    "\n",
    "# Mostrar puntuación media\n",
    "print('Error MSE medio: ', sum(mse_loss_list)/5)\n",
    "print('Error MAE medio: ', sum(mae_score_list)/5)\n",
    "print('Puntuación R2 media: ', sum(r2_score_list)/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este descenso del *learning rate*, se han obtenido los siguientes resultados:\n",
    "\n",
    "\n",
    "| Partición | MSE     | MAE     | R2      |\n",
    "| :-------: | :-----: | :-----: | :-----: |\n",
    "|  K = 1    | 0.77174 | 0.70025 | -0.01081 |\n",
    "|  K = 2    | 0.92076 | 0.68240 | -0.20601 |\n",
    "|  K = 3    | 0.84066 | 0.76044 | -0.10556 |\n",
    "|  K = 4    | 0.90805 | 0.71697 | -0.19265 |\n",
    "|  K = 5    | 0.89405 | 0.74436 | -0.17091 |\n",
    "|  media    | 0.86705 | 0.72088 | -0.13719 |\n",
    "\n",
    "Comparamos estos resultados con los obtenidos con el modelo original:\n",
    "\n",
    "| Modelo       | MSE medio  | MAE medio | R2 medio |\n",
    "| :----------: | :--------: | :-------: | :------: |\n",
    "| Básico   | 0.51043    | 0.55334   | 0.33056  |\n",
    "| Mayor lr | 0.86705 | 0.72088 | -0.13719 |\n",
    "\n",
    "Con bastante diferencia, se aprecia que el rendimiento del modelo ha empeorado respecto del modelo original y de los modelos anteriores.\n",
    "Incrementar el *learning rate* en exceso povocaría oscilaciones en el ajuste del modelo que impedirían al mismo avanzar en la dirección del gradiente hacia los parámetros más óptimos.\n",
    "\n",
    "De todos los modelos tratados, se concluye que el modelo con mayor número de capas intermedias presenta un rendimiento superior al resto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación del riesgo de abandono de los clientes de un banco\n",
    "\n",
    "Ahora trataremos el uso de la redes neuronales *MLP* sobre un segundo problema: **La clasificación del riesgo de abandono de los clientes de un banco**.\n",
    "\n",
    "Dado un *dataset* que recoge datos personales y bancarios de 10000 clientes, se pretende predecir si existe o no riesgo de abandono de estos clientes al banco al que pertenecen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga del *dataset*\n",
    "\n",
    "Procedemos, en primer lugar, a cargar el *dataset*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset\n",
    "clients = pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis exploratorio de datos\n",
    "\n",
    "Analizamos brevemente el *dataset* cargado para obtener información preliminar sobre su estructura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conocer el tipo de dato de cada variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null int64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "clients.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcular estadísticos básicos sobre cada variable numérica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>5.012800</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.892174</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age        Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800      5.012800   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806      2.892174   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000      0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000      3.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000      5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000      7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000     10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizar las 5 primeras filas del *dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento del *dataset*\n",
    "\n",
    "A continuación, preprocesamos el *dataset* y lo particionaremos en los subconjuntos de entrenamiento y test.\n",
    "\n",
    "Primeramente, separamos los datos de la etiqueta que se pretende predecir (*Exited*).Por otra parte, en los datos excluiremos las variables *row_number* y *CustomerId* al no resultar útiles para la predición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 'France', 'Female', ..., 1, 1, 101348.88],\n",
       "       [608, 'Spain', 'Female', ..., 0, 1, 112542.58],\n",
       "       [502, 'France', 'Female', ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [709, 'France', 'Female', ..., 0, 1, 42085.58],\n",
       "       [772, 'Germany', 'Male', ..., 1, 0, 92888.52],\n",
       "       [792, 'France', 'Female', ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = clients.iloc[:,3:13].values\n",
    "y = clients['Exited'].values\n",
    "\n",
    "# Mostrar el conjunto de datos\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunas de las variables del *dataset* constituyen variables categóricas que no pueden ser tratadas por las redes *MLP* de forma directa.\n",
    "\n",
    "Se hace necesario **binarizar** estas variables categóricas (convertir cada variable categórica en tantas variables binarias como valores diferentes presente, establecer a 1 la variable binaria correspondiente al valor de la variable categórica original y establecer el resto de valores a 0). Ello se ejecutará con la utilidad *LabelEncoder*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarizamos cada una de las variables categóricas\n",
    "label_encoder_1 = LabelEncoder()\n",
    "X[:, 1] = label_encoder_1.fit_transform(X[:, 1])\n",
    "\n",
    "label_encoder_2 = LabelEncoder()\n",
    "X[:, 2] = label_encoder_2.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos el conjunto de entrenamiento en dos subconjuntos: *train* y *test*, reservando el 20% de las instancias para el conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para terminar el preprocesamiento, **normalizamos** todas las variables del *dataset*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train) # Normalizar variables del conjunto de train\n",
    "X_test = scaler.transform(X_test)        # Normalizar variables del conjunto de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de modelos\n",
    "\n",
    "Una vez preprocesados los datos, procedemos a definir la arquitectura del modelo y a ejecutar el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_clients_MLP():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Primera capa oculta\n",
    "    model.add(Dense(6, activation='relu', input_shape=(10,)))\n",
    "    \n",
    "    # Segunda capa oculta\n",
    "    model.add(Dense(6, activation='relu'))\n",
    "    \n",
    "    # Tercera capa oculta\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar la arquitectura\n",
    "model_clients = model_clients_MLP()\n",
    "model_clients.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutar el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3327 - accuracy: 0.8604\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3319 - accuracy: 0.8648\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3330 - accuracy: 0.8621\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3316 - accuracy: 0.8609\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3333 - accuracy: 0.8606\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3329 - accuracy: 0.8616\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3332 - accuracy: 0.8610\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3333 - accuracy: 0.8610\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3321 - accuracy: 0.8625\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3329 - accuracy: 0.8619\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3328 - accuracy: 0.8629\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3319 - accuracy: 0.8635\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3333 - accuracy: 0.8622\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3328 - accuracy: 0.8622\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3322 - accuracy: 0.8618\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3319 - accuracy: 0.8621\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3326 - accuracy: 0.8624\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3327 - accuracy: 0.8608\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3325 - accuracy: 0.8626\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3314 - accuracy: 0.8635\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3321 - accuracy: 0.8633\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3321 - accuracy: 0.8643\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3320 - accuracy: 0.8614\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3323 - accuracy: 0.8633\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3323 - accuracy: 0.8618\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3312 - accuracy: 0.8645\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3322 - accuracy: 0.8633\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3324 - accuracy: 0.8631\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3323 - accuracy: 0.8639\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3315 - accuracy: 0.8645\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3318 - accuracy: 0.8631\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3321 - accuracy: 0.8625\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3317 - accuracy: 0.8620\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3317 - accuracy: 0.8631\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3315 - accuracy: 0.8633\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3321 - accuracy: 0.8611\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3318 - accuracy: 0.8622\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3317 - accuracy: 0.8621\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3319 - accuracy: 0.8636\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3320 - accuracy: 0.8618\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3314 - accuracy: 0.8637\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3321 - accuracy: 0.8634\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3310 - accuracy: 0.8636\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3315 - accuracy: 0.8629\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3310 - accuracy: 0.8625\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3314 - accuracy: 0.8626\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3315 - accuracy: 0.8646\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3314 - accuracy: 0.8626\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3315 - accuracy: 0.8646\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3307 - accuracy: 0.8644\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3309 - accuracy: 0.8622\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3313 - accuracy: 0.8639\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3313 - accuracy: 0.8626\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3318 - accuracy: 0.8624\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3320 - accuracy: 0.8626\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3319 - accuracy: 0.8610\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3306 - accuracy: 0.8627\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3308 - accuracy: 0.8631\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3314 - accuracy: 0.8611\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3304 - accuracy: 0.8625\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3312 - accuracy: 0.8629\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3313 - accuracy: 0.8629\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3314 - accuracy: 0.8618\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 0.3315 - accuracy: 0.8644\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 0.3318 - accuracy: 0.8640\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3309 - accuracy: 0.8641\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 0.3318 - accuracy: 0.8640\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 0.3311 - accuracy: 0.8645\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3312 - accuracy: 0.8639\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 0.3313 - accuracy: 0.8630\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 0.3311 - accuracy: 0.8634\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3318 - accuracy: 0.8631\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3318 - accuracy: 0.8633\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3311 - accuracy: 0.8639\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3313 - accuracy: 0.8634\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3311 - accuracy: 0.8626\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3314 - accuracy: 0.8621\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3310 - accuracy: 0.8616\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3310 - accuracy: 0.8630\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3303 - accuracy: 0.8615\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3312 - accuracy: 0.8643\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3309 - accuracy: 0.8625\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3305 - accuracy: 0.8652\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 0.3311 - accuracy: 0.8625\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 12s 1ms/step - loss: 0.3313 - accuracy: 0.8608\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 0.3309 - accuracy: 0.8622\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3314 - accuracy: 0.8629\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3312 - accuracy: 0.8636\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3316 - accuracy: 0.8614\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3311 - accuracy: 0.8644\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3309 - accuracy: 0.8641\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3309 - accuracy: 0.8630\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3303 - accuracy: 0.8655\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3309 - accuracy: 0.8637\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3308 - accuracy: 0.8640\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3314 - accuracy: 0.8624\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 0.3304 - accuracy: 0.8634\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 0.3306 - accuracy: 0.8636\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 0.3310 - accuracy: 0.8630\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3308 - accuracy: 0.8645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f86135a51d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_clients.fit(X_train, y_train, epochs=100, batch_size=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 19us/step\n",
      "2000/2000 [==============================] - 0s 25us/step\n",
      "Accuracy del modelo:  0.19200000166893005\n",
      "Loss del modelo:  51571.4255\n",
      "Matriz de confusión:\n",
      "[[   0 1616]\n",
      " [   0  384]]\n",
      "Precisión del modelo: 0.192\n",
      "Recall del modelo: 1.0\n",
      "F1-score del modelo: 0.32214765100671144\n",
      "Métrica Cohen's kappa del modelo: 0.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_clients.predict(X_test, verbose=True)\n",
    "y_pred = (y_pred>=0.5).astype('int64').squeeze()\n",
    "\n",
    "# Evaluar la puntuación\n",
    "score = model_clients.evaluate(X_test, y_test, verbose=True)\n",
    "\n",
    "print('Accuracy del modelo: ', score[1])\n",
    "print('Loss del modelo: ', score[0])\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de confusión:')\n",
    "print(conf)\n",
    "\n",
    "# Precisión del modelo\n",
    "print('Precisión del modelo: {}'.format(precision_score(y_test, y_pred)))\n",
    "\n",
    "# Recall del modelo\n",
    "print('Recall del modelo: {}'.format(recall_score(y_test, y_pred)))\n",
    "\n",
    "# F1-score del modelo\n",
    "print('F1-score del modelo: {}'.format(f1_score(y_test, y_pred)))\n",
    "\n",
    "# Cohen's kappa del modelo\n",
    "print('Métrica Cohen\\'s kappa del modelo: {}'.format(cohen_kappa_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que el rendimiento de este modelo es pésimo, se ha obtenido un clasificador trivial que clasifica todos los patrones como pertenencientes a la clase negativa. Analizando la evolución de las métricas de *accuracy* y *loss* medidas sobre el conjunto de entrenamiento, percibimos **ciertos efectos oscilatorios** durante el entrenamiento del modelo.\n",
    "\n",
    "Repetimos el entrenamiento con la anterior arquitectura considerando un valor de *learning rate* de $10^{-5}$ para el optimizador Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.6666 - accuracy: 0.6410\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.6282 - accuracy: 0.7400\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.5943 - accuracy: 0.7729\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.5654 - accuracy: 0.7856\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.5414 - accuracy: 0.7890\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.5223 - accuracy: 0.7900\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.5077 - accuracy: 0.7901\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.4969 - accuracy: 0.7920\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4890 - accuracy: 0.7925\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4829 - accuracy: 0.7928\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.4782 - accuracy: 0.7933\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4745 - accuracy: 0.7933\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4716 - accuracy: 0.7934\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4690 - accuracy: 0.7933\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4669 - accuracy: 0.7933\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4650 - accuracy: 0.7934\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4632 - accuracy: 0.7933\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.4617 - accuracy: 0.7934\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4603 - accuracy: 0.7931\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.4589 - accuracy: 0.7931\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4577 - accuracy: 0.7931\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4565 - accuracy: 0.7931\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4555 - accuracy: 0.7929\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4545 - accuracy: 0.7929\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4535 - accuracy: 0.7926\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4526 - accuracy: 0.7924\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4518 - accuracy: 0.7928\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4510 - accuracy: 0.7929\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.4503 - accuracy: 0.7928\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4495 - accuracy: 0.7928\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4489 - accuracy: 0.7925\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4482 - accuracy: 0.7933\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4475 - accuracy: 0.7935\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4469 - accuracy: 0.7935\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4463 - accuracy: 0.7939\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.4457 - accuracy: 0.7936\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4452 - accuracy: 0.7936\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4446 - accuracy: 0.7937\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4441 - accuracy: 0.7935\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4436 - accuracy: 0.7943\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4431 - accuracy: 0.7945\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4426 - accuracy: 0.7951\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4421 - accuracy: 0.7960\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4416 - accuracy: 0.7962\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4411 - accuracy: 0.7966\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4407 - accuracy: 0.7971\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4402 - accuracy: 0.7979\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4397 - accuracy: 0.7983\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4393 - accuracy: 0.7985\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4388 - accuracy: 0.7989\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4384 - accuracy: 0.7991\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4380 - accuracy: 0.7999\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4375 - accuracy: 0.8001\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4371 - accuracy: 0.8005\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4367 - accuracy: 0.8009\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4363 - accuracy: 0.8005\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4359 - accuracy: 0.8012\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4355 - accuracy: 0.8016\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4351 - accuracy: 0.8023\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4347 - accuracy: 0.8029\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4343 - accuracy: 0.8037\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4339 - accuracy: 0.8045\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.4335 - accuracy: 0.8045\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4331 - accuracy: 0.8039\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4328 - accuracy: 0.8040\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4324 - accuracy: 0.8054\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4320 - accuracy: 0.8064\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.4316 - accuracy: 0.8065\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4312 - accuracy: 0.8067\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4308 - accuracy: 0.8075\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4305 - accuracy: 0.8073\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4301 - accuracy: 0.8085\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4297 - accuracy: 0.8087\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4294 - accuracy: 0.8091\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.4290 - accuracy: 0.8100\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4286 - accuracy: 0.8100\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4282 - accuracy: 0.8100\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4279 - accuracy: 0.8096\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.4275 - accuracy: 0.8100\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.4271 - accuracy: 0.8111\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.4267 - accuracy: 0.8123\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4263 - accuracy: 0.8125\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4259 - accuracy: 0.8126\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4255 - accuracy: 0.8127\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4251 - accuracy: 0.8136\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.4247 - accuracy: 0.8131\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4242 - accuracy: 0.8136\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4238 - accuracy: 0.8141\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4234 - accuracy: 0.8139\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4230 - accuracy: 0.8144\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4226 - accuracy: 0.8149\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.4222 - accuracy: 0.8150\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4217 - accuracy: 0.8151\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4213 - accuracy: 0.8155\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4209 - accuracy: 0.8158\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4204 - accuracy: 0.8164\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4200 - accuracy: 0.8164\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4195 - accuracy: 0.8164\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4191 - accuracy: 0.8169\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4187 - accuracy: 0.8173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f8611c567b8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparar la arquitectura\n",
    "model_clients2 = model_clients_MLP()\n",
    "model_clients2.compile(optimizer=Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model_clients2.fit(X_train, y_train, epochs=100, batch_size=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 15us/step\n",
      "2000/2000 [==============================] - 0s 26us/step\n",
      "Accuracy del modelo:  0.737500011920929\n",
      "Loss del modelo:  2604.3631162109373\n",
      "Matriz de confusión:\n",
      "[[1407  209]\n",
      " [ 316   68]]\n",
      "Precisión del modelo: 0.24548736462093862\n",
      "Recall del modelo: 0.17708333333333334\n",
      "F1-score del modelo: 0.20574886535552195\n",
      "Métrica Cohen's kappa del modelo: 0.053426416074081495\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_clients2.predict(X_test, verbose=True)\n",
    "y_pred = (y_pred>=0.5).astype('int64').squeeze()\n",
    "\n",
    "# Evaluar la puntuación\n",
    "score = model_clients2.evaluate(X_test, y_test, verbose=True)\n",
    "\n",
    "print('Accuracy del modelo: ', score[1])\n",
    "print('Loss del modelo: ', score[0])\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de confusión:')\n",
    "print(conf)\n",
    "\n",
    "# Precisión del modelo\n",
    "print('Precisión del modelo: {}'.format(precision_score(y_test, y_pred)))\n",
    "\n",
    "# Recall del modelo\n",
    "print('Recall del modelo: {}'.format(recall_score(y_test, y_pred)))\n",
    "\n",
    "# F1-score del modelo\n",
    "print('F1-score del modelo: {}'.format(f1_score(y_test, y_pred)))\n",
    "\n",
    "# Cohen's kappa del modelo\n",
    "print('Métrica Cohen\\'s kappa del modelo: {}'.format(cohen_kappa_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que el descenso de este *learning rate* ha permitido incrementar en gran medida el rendimiento del modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
